{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_udacity_comleted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipulgote1999/machine-learning-udacity/blob/master/svm_udacity_comleted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qA3JjdSxoFd",
        "colab_type": "code",
        "outputId": "608b1774-f8a1-4a8c-cf4c-5f23f9ed123b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "!pip install scikit-learn==0.18\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/51/4b2c24523ca21e9f3efadff99096067f1fdb20dd0b2a4582d68e63612a59/scikit_learn-0.18-cp27-cp27mu-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 34.8MB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement scikit-learn>=0.19.1, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.20.3\n",
            "    Uninstalling scikit-learn-0.20.3:\n",
            "      Successfully uninstalled scikit-learn-0.20.3\n",
            "Successfully installed scikit-learn-0.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GeD2IsGyfYd",
        "colab_type": "code",
        "outputId": "204f93f4-92d7-4f16-b4af-cd24123d2dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install scipy==0.18.1\n",
        "!pip install numpy==1.11.2\n",
        "!pip install nltk==3.2.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==0.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/cb/8e74d28e1519b34636e4d985d49d01c23778064e01eb102914f844cd6051/scipy-0.18.1-cp27-cp27mu-manylinux1_x86_64.whl (40.3MB)\n",
            "\u001b[K     |████████████████████████████████| 40.3MB 73.4MB/s \n",
            "\u001b[31mERROR: cvxpy 1.0.15 has requirement scipy>=1.1.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.3.9 has requirement scipy>=0.19, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mir-eval 0.5 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.6.3 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement scikit-learn>=0.19.1, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.4.0 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Found existing installation: scipy 1.2.2\n",
            "    Uninstalling scipy-1.2.2:\n",
            "      Successfully uninstalled scipy-1.2.2\n",
            "Successfully installed scipy-0.18.1\n",
            "Collecting numpy==1.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/d5/3433e015f3e4a1f309dbb110e8557947f68887fe9b8438d50a4b7790a954/numpy-1.11.2-cp27-cp27mu-manylinux1_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 51.1MB/s \n",
            "\u001b[31mERROR: xarray 0.11.3 has requirement numpy>=1.12, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 1.14.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-hub 0.5.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.4.0 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.6.3 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.14.0 has requirement numpy<2.0,>=1.14.5, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement scikit-learn>=0.19.1, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 0.24.2 has requirement numpy>=1.12.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 0.14.0 has requirement numpy>=1.14, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: autograd 1.2 has requirement numpy>=1.12, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mir-eval 0.5 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.3.9 has requirement numpy>=1.13, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.3.9 has requirement scipy>=0.19, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pymc3 3.6 has requirement numpy>=1.13.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement numpy>=1.13.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: gensim 3.6.0 has requirement numpy>=1.11.3, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.15 has requirement numpy>=1.14, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.15 has requirement scipy>=1.1.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.1.6 has requirement numpy>=1.15.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed numpy-1.11.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk==3.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/85/8fa6f8c488507aab7d6234ce754bbbe61bfeb8382489785e2d764bf8f52a/nltk-3.2.1.tar.gz (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 28.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 34.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 39.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 39.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 43.4MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 44.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 43.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 45.7MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 45.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112kB 45.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 45.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 45.2MB/s eta 0:00:01\r\u001b[K     |████                            | 143kB 45.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 45.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 604kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 686kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 716kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 798kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 849kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 880kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890kB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 931kB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 962kB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 993kB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0MB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0MB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 45.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 45.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.2.1-cp27-none-any.whl size=1316641 sha256=81326b16aec66860e324990cbfc373b32df6c894b350d41555e7586e1285d2ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/09/54/c7baf815a67c5f19ec23752715885b1ce25c9617e8a1c25da3\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzpFtKZAvtrB",
        "colab_type": "code",
        "outputId": "88dd5821-93a6-4721-d9c4-7c2d3a892bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!git clone https://github.com/udacity/ud120-projects.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ud120-projects'...\n",
            "remote: Enumerating objects: 5046, done.\u001b[K\n",
            "remote: Total 5046 (delta 0), reused 0 (delta 0), pack-reused 5046\u001b[K\n",
            "Receiving objects: 100% (5046/5046), 19.64 MiB | 3.47 MiB/s, done.\n",
            "Resolving deltas: 100% (4372/4372), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqG_FU5_3ztF",
        "colab_type": "code",
        "outputId": "a85d513e-9264-42e4-a859-04804c2e50b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#!/usr/bin/python\n",
        "\n",
        "import pickle\n",
        "import cPickle\n",
        "import numpy\n",
        "\n",
        "from sklearn import cross_validation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(words_file = \"/content/ud120-projects/tools/word_data.pkl\", authors_file=\"/content/ud120-projects/tools/email_authors.pkl\"):\n",
        "    \"\"\" \n",
        "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
        "        and the corresponding authors (by default email_authors.pkl) and performs\n",
        "        a number of preprocessing steps:\n",
        "            -- splits into training/testing sets (10% testing)\n",
        "            -- vectorizes into tfidf matrix\n",
        "            -- selects/keeps most helpful features\n",
        "\n",
        "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
        "\n",
        "        4 objects are returned:\n",
        "            -- training/testing features\n",
        "            -- training/testing labels\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ### the words (features) and authors (labels), already largely preprocessed\n",
        "    ### this preprocessing will be repeated in the text learning mini-project\n",
        "    authors_file_handler = open(authors_file, \"r\")\n",
        "    authors = pickle.load(authors_file_handler)\n",
        "    authors_file_handler.close()\n",
        "\n",
        "    words_file_handler = open(words_file, \"r\")\n",
        "    word_data = cPickle.load(words_file_handler)\n",
        "    words_file_handler.close()\n",
        "\n",
        "    ### test_size is the percentage of events assigned to the test set\n",
        "    ### (remainder go into training)\n",
        "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "    ### text vectorization--go from strings to lists of numbers\n",
        "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                 stop_words='english')\n",
        "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
        "    features_test_transformed  = vectorizer.transform(features_test)\n",
        "\n",
        "\n",
        "\n",
        "    ### feature selection, because text is super high dimensional and \n",
        "    ### can be really computationally chewy as a result\n",
        "    selector = SelectPercentile(f_classif, percentile=10)\n",
        "    selector.fit(features_train_transformed, labels_train)\n",
        "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
        "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
        "\n",
        "    ### info on the data\n",
        "    print \"no. of Chris training emails:\", sum(labels_train)\n",
        "    print \"no. of Sara training emails:\", len(labels_train)-sum(labels_train)\n",
        "    \n",
        "    return features_train_transformed, features_test_transformed, labels_train, labels_test\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16YL5Bq42g3R",
        "colab_type": "code",
        "outputId": "0cfb5eec-0791-434d-efbe-eff4e4154d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "\n",
        "\n",
        "\"\"\" \n",
        "    This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
        "\n",
        "    Use a SVM to identify emails from the Enron corpus by their authors:    \n",
        "    Sara has label 0\n",
        "    Chris has label 1\n",
        "\"\"\"\n",
        "    \n",
        "import sys\n",
        "from time import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#########################################################\n",
        "### your code goes here ###\n",
        "\n",
        "#########################################################\n",
        "\n",
        "### features_train and features_test are the features for the training\n",
        "### and testing datasets, respectively\n",
        "### labels_train and labels_test are the corresponding item labels\n",
        "features_train, features_test, labels_train, labels_test = preprocess()\n",
        "model=svm.SVC(kernel='rbf',C=10000)\n",
        "#features_train = features_train[:len(features_train)/100] \n",
        "#labels_train = labels_train[:len(labels_train)/100] \n",
        "print(len(labels_train))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:1039: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(mask.dtype, np.int):\n",
            "/usr/local/lib/python2.7/dist-packages/scipy/stats/stats.py:1626: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "no. of Chris training emails: 7936\n",
            "no. of Sara training emails: 7884\n",
            "15820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5iZcz7j_QvG",
        "colab_type": "code",
        "outputId": "7e9b3faa-bdcf-4609-bf6e-986b9a50be5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.fit(features_train,labels_train)\n",
        "t0=time()\n",
        "\n",
        "pred=model.predict(features_test)\n",
        "\n",
        "print \"training time:\", round(time()-t0, 3), \"s\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training time: 17.354 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIs9W6cPzyGl",
        "colab_type": "code",
        "outputId": "296bb9e8-5afb-4fb3-ca8d-26eb09b84ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s=[]\n",
        "for i in pred:\n",
        "  if i==1:\n",
        "    s.append(i)\n",
        "print(len(s))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YoUNsIP_rmJ",
        "colab_type": "text"
      },
      "source": [
        "no. of Chris training emails: 7936\n",
        "no. of Sara training emails: 7884\n",
        "# **for linear kernal**\n",
        "1.  training time with 100% data: 25.417 s\n",
        "2.  training time with 1% data:1.249 s\n",
        "3.  training time with rbf kernal and 1% data =training time: 1.395 s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-_MW89L8Wsl",
        "colab_type": "code",
        "outputId": "516e65bf-30a4-4ba7-85e0-4ac95760f068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy=accuracy_score(labels_test,pred)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9908987485779295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYGA9Pf7_kee",
        "colab_type": "text"
      },
      "source": [
        "# **accuracy with kernal='linear'**\n",
        "1.    acc_whole datasets=0.9840728100113766\n",
        "2.   acc with 1% dataset =0.8845278725824801\n",
        "3.   acc with kerenal='rbf'and 1% data =0.6160409556313993\n",
        "4.   acc with previous kernal and changing value of  c:\n",
        "\n",
        "   * c=10000 acc=0.8924914675767918\n",
        "   * c=1000 acc=0.8213879408418657\n",
        "   * c=100 acc=0.6160409556313993\n",
        "   * c=10 acc=0.6160409556313993\n",
        "\n"
      ]
    }
  ]
}